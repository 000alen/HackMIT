{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Puzzle3",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4kQUWdRND2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3705ceb1-aa41-46ba-829d-8dfb62a238cd"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.7.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shjvWrN0QhJp"
      },
      "source": [
        "import transformers \n",
        "import datasets\n",
        "import torch\n",
        "import numpy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sipupqcBSAu-"
      },
      "source": [
        "# device = torch.device(\"cuda\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbdK3ibiQ1Hw"
      },
      "source": [
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"HackMIT/double-agent\")\n",
        "# model.to(device)\n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"HackMIT/double-agent\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDm0Z-aovsRF"
      },
      "source": [
        "# train_dataset = datasets.load_dataset(\"glue\", \"sst2\")[\"train\"]\n",
        "# train_dataset = train_dataset.map(\n",
        "#     lambda examples: {\n",
        "#         \"labels\": examples[\"label\"]\n",
        "#     }\n",
        "# )\n",
        "# train_dataset = train_dataset.map(\n",
        "#     lambda examples: {\n",
        "#         \"sentence\": torch.LongTensor(\n",
        "#             tokenizer.encode(\n",
        "#                 examples[\"sentence\"], \n",
        "#                 max_length=512, \n",
        "#                 padding=\"max_length\", \n",
        "#                 truncation=True\n",
        "#             )\n",
        "#         ).to(device)\n",
        "#     }\n",
        "# )\n",
        "# train_dataset = train_dataset.map(\n",
        "#     lambda examples: {\n",
        "#         \"input_ids\": examples[\"sentence\"]\n",
        "#     }\n",
        "# )\n",
        "# train_dataset.set_format(\"torch\", columns=[\"sentence\", \"labels\", \"input_ids\"])\n",
        "\n",
        "# train_dataloader = torch.utils.data.DataLoader(train_dataset)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCn8kTgUvxw8",
        "outputId": "dd2eb317-74df-4260-d152-57f1b51fcb28"
      },
      "source": [
        "validation_dataset = datasets.load_dataset(\"glue\", \"sst2\")[\"validation\"]\n",
        "validation_dataset = validation_dataset.map(\n",
        "    lambda examples: {\n",
        "        \"labels\": examples[\"label\"]\n",
        "    }\n",
        ")\n",
        "validation_dataset = validation_dataset.map(\n",
        "    lambda examples: {\n",
        "        \"sentence\": torch.LongTensor(\n",
        "            tokenizer.encode(\n",
        "                examples[\"sentence\"], \n",
        "                max_length=512, \n",
        "                padding=\"max_length\", \n",
        "                truncation=True\n",
        "            )\n",
        "        ) # .to(device)\n",
        "    }\n",
        ")\n",
        "validation_dataset = validation_dataset.map(\n",
        "    lambda examples: {\n",
        "        \"input_ids\": examples[\"sentence\"]\n",
        "    }\n",
        ")\n",
        "validation_dataset.set_format(\"torch\", columns=[\"sentence\", \"labels\", \"input_ids\"])\n",
        "\n",
        "validation_dataloader = torch.utils.data.DataLoader(validation_dataset)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-7c1e335814a61793.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-3a018c669ec25937.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-9aa0cb910016f3c1.arrow\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LoHKOdFwBqQ"
      },
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        print(f\"epoch: {epoch}\")\n",
        "        for batch, Z in enumerate(dataloader):        \n",
        "            X = Z[\"sentence\"]\n",
        "            y = Z[\"labels\"]\n",
        "\n",
        "            pred = model(X).logits\n",
        "            loss = loss_fn(pred, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch % 100 == 0:\n",
        "                loss, current = loss.item(), batch * len(X)\n",
        "                print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "        print()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ffiMxfKv2ua",
        "outputId": "2fb22ffb-b8ba-4960-d769-b04df34ec71a"
      },
      "source": [
        "training_args = transformers.TrainingArguments(\"with_loss_and_optimizer\")\n",
        "\n",
        "# trainer = transformers.Trainer(\n",
        "#     model=model, \n",
        "#     args=training_args, \n",
        "#     train_dataset=train_dataset, \n",
        "#     eval_dataset=validation_dataset,\n",
        "# )\n",
        " \n",
        "# trainer.train()\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "\n",
        "train(validation_dataloader, model, loss_fn, optimizer)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0\n",
            "loss: 0.039131  [    0/  872]\n",
            "loss: 0.707561  [  100/  872]\n",
            "loss: 0.572271  [  200/  872]\n",
            "loss: 0.295413  [  300/  872]\n",
            "loss: 0.230474  [  400/  872]\n",
            "loss: 0.491547  [  500/  872]\n",
            "loss: 0.060512  [  600/  872]\n",
            "loss: 0.624651  [  700/  872]\n",
            "loss: 0.369048  [  800/  872]\n",
            "\n",
            "epoch: 1\n",
            "loss: 0.236848  [    0/  872]\n",
            "loss: 1.012551  [  100/  872]\n",
            "loss: 0.123901  [  200/  872]\n",
            "loss: 1.058579  [  300/  872]\n",
            "loss: 0.202542  [  400/  872]\n",
            "loss: 0.101293  [  500/  872]\n",
            "loss: 0.044065  [  600/  872]\n",
            "loss: 0.315713  [  700/  872]\n",
            "loss: 0.723777  [  800/  872]\n",
            "\n",
            "epoch: 2\n",
            "loss: 0.045602  [    0/  872]\n",
            "loss: 2.348440  [  100/  872]\n",
            "loss: 0.115970  [  200/  872]\n",
            "loss: 0.118544  [  300/  872]\n",
            "loss: 0.249323  [  400/  872]\n",
            "loss: 0.063637  [  500/  872]\n",
            "loss: 0.036809  [  600/  872]\n",
            "loss: 0.907577  [  700/  872]\n",
            "loss: 0.492162  [  800/  872]\n",
            "\n",
            "epoch: 3\n",
            "loss: 0.024647  [    0/  872]\n",
            "loss: 1.930144  [  100/  872]\n",
            "loss: 0.121676  [  200/  872]\n",
            "loss: 0.041144  [  300/  872]\n",
            "loss: 0.262919  [  400/  872]\n",
            "loss: 0.158130  [  500/  872]\n",
            "loss: 0.070623  [  600/  872]\n",
            "loss: 0.064278  [  700/  872]\n",
            "loss: 0.685502  [  800/  872]\n",
            "\n",
            "epoch: 4\n",
            "loss: 0.031015  [    0/  872]\n",
            "loss: 0.773830  [  100/  872]\n",
            "loss: 0.079258  [  200/  872]\n",
            "loss: 0.412873  [  300/  872]\n",
            "loss: 0.561267  [  400/  872]\n",
            "loss: 0.063443  [  500/  872]\n",
            "loss: 0.044554  [  600/  872]\n",
            "loss: 0.059185  [  700/  872]\n",
            "loss: 0.943432  [  800/  872]\n",
            "\n",
            "epoch: 5\n",
            "loss: 0.019077  [    0/  872]\n",
            "loss: 0.992577  [  100/  872]\n",
            "loss: 0.036326  [  200/  872]\n",
            "loss: 3.158185  [  300/  872]\n",
            "loss: 0.302443  [  400/  872]\n",
            "loss: 0.063018  [  500/  872]\n",
            "loss: 0.046142  [  600/  872]\n",
            "loss: 0.856944  [  700/  872]\n",
            "loss: 0.042123  [  800/  872]\n",
            "\n",
            "epoch: 6\n",
            "loss: 0.009455  [    0/  872]\n",
            "loss: 1.025052  [  100/  872]\n",
            "loss: 0.143338  [  200/  872]\n",
            "loss: 3.408409  [  300/  872]\n",
            "loss: 0.013452  [  400/  872]\n",
            "loss: 0.067236  [  500/  872]\n",
            "loss: 0.066219  [  600/  872]\n",
            "loss: 0.835935  [  700/  872]\n",
            "loss: 0.040173  [  800/  872]\n",
            "\n",
            "epoch: 7\n",
            "loss: 0.022616  [    0/  872]\n",
            "loss: 0.317331  [  100/  872]\n",
            "loss: 0.096509  [  200/  872]\n",
            "loss: 2.780882  [  300/  872]\n",
            "loss: 0.007750  [  400/  872]\n",
            "loss: 0.052118  [  500/  872]\n",
            "loss: 0.031224  [  600/  872]\n",
            "loss: 0.018545  [  700/  872]\n",
            "loss: 0.053532  [  800/  872]\n",
            "\n",
            "epoch: 8\n",
            "loss: 0.005783  [    0/  872]\n",
            "loss: 0.021291  [  100/  872]\n",
            "loss: 0.140204  [  200/  872]\n",
            "loss: 0.285212  [  300/  872]\n",
            "loss: 0.361706  [  400/  872]\n",
            "loss: 0.041109  [  500/  872]\n",
            "loss: 0.023453  [  600/  872]\n",
            "loss: 0.016480  [  700/  872]\n",
            "loss: 0.530293  [  800/  872]\n",
            "\n",
            "epoch: 9\n",
            "loss: 0.009941  [    0/  872]\n",
            "loss: 0.319461  [  100/  872]\n",
            "loss: 0.104872  [  200/  872]\n",
            "loss: 2.243747  [  300/  872]\n",
            "loss: 0.068909  [  400/  872]\n",
            "loss: 0.035495  [  500/  872]\n",
            "loss: 0.060825  [  600/  872]\n",
            "loss: 0.013949  [  700/  872]\n",
            "loss: 0.075780  [  800/  872]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKvmoMcqvzyR"
      },
      "source": [
        "metric = datasets.load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = numpy.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "Lr0BCbX_v4_O",
        "outputId": "9f01a942-92cd-4ec2-a2c9-7475972491f0"
      },
      "source": [
        "trainer = transformers.Trainer(\n",
        "    model=model, \n",
        "    args=training_args, \n",
        "    train_dataset=validation_dataset, \n",
        "    eval_dataset=validation_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "trainer.evaluate()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence, idx.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 872\n",
            "  Batch size = 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='109' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [109/109 00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.8967889908256881,\n",
              " 'eval_loss': 0.28726258873939514,\n",
              " 'eval_runtime': 0.8538,\n",
              " 'eval_samples_per_second': 1021.308,\n",
              " 'eval_steps_per_second': 127.663}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0udBpWebv7_A"
      },
      "source": [
        "torch.save(model.state_dict(), \"with_loss_and_optimizer/model.pt\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFbwcjfd2yy8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}