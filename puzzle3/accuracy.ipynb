{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import transformers \r\n",
    "import torch\r\n",
    "import datasets\r\n",
    "\r\n",
    "device = torch.device(\"cuda\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"HackMIT/double-agent\")\r\n",
    "model.load_state_dict(torch.load(\"Seba 0.89.pt\"))\r\n",
    "model.eval()\r\n",
    "\r\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"HackMIT/double-agent\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# output = model(torch.LongTensor([tokenizer.encode(\"Sad\", max_length=66, padding=\"max_length\", truncation=True)]))\r\n",
    "# scores = output.logits.softmax(1)\r\n",
    "\r\n",
    "# scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# prediction = scores.argmax().item()\r\n",
    "\r\n",
    "# prediction"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def check_accuracy(loader, model):\r\n",
    "    num_correct = 0\r\n",
    "    num_samples = 0\r\n",
    "    \r\n",
    "    with torch.no_grad():\r\n",
    "        for _ in loader:\r\n",
    "            x = _[\"sentence\"]\r\n",
    "            y = _[\"label\"]\r\n",
    "            \r\n",
    "            # output = model(torch.LongTensor([x]))\r\n",
    "            output = model(x)\r\n",
    "            scores = output.logits.softmax(1)\r\n",
    "            prediction = scores.argmax().item()\r\n",
    "            \r\n",
    "            num_correct += 1 if prediction == y.item() else 0\r\n",
    "            num_samples += 1\r\n",
    "        \r\n",
    "        print(f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "dataset = datasets.load_dataset(\"glue\", \"sst2\")[\"validation\"]\r\n",
    "dataset = dataset.map(lambda validations: {\"labels\": validations[\"label\"]})\r\n",
    "dataset = dataset.map(lambda validations: {\"sentence\": tokenizer.encode(validations[\"sentence\"], add_special_tokens=True)})\r\n",
    "dataset.set_format(\"torch\")\r\n",
    "\r\n",
    "dataloader = torch.utils.data.DataLoader(dataset)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Reusing dataset glue (C:\\Users\\alenk\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Loading cached processed dataset at C:\\Users\\alenk\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-10319e22486697fe.arrow\n",
      "Loading cached processed dataset at C:\\Users\\alenk\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-e68eedea13443af3.arrow\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "check_accuracy(dataloader, model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Got 764 / 872 with accuracy 87.61\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "a6998462f6ded608d092aa543d45656b83249658fd3f874a85d4e2308b5f8713"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}